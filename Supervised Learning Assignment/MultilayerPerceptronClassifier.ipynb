{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de clasificación con Perceptrón Multicapa \n",
    "## Autora: Sandra Alonso Paz, estudiante del Máster en Biología Computacional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importación de los datos\n",
    "### 1. Importar los datos del CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "path ='dataset18.csv'\n",
    "data = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Creamos las dos variables que utilizaremos en el modelo\n",
    "   \n",
    "    X = Atributos del modelo (columnas del CSV)\n",
    "    \n",
    "    Y = Columna target (la que queremos predecir a partir del resto de columnas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,2:23] #Seleccionamos todas las columnas quitando la columna Unnamed (id de la fila ) y la columna Target.\n",
    "Y = []\n",
    "\n",
    "# Como la columna target esta compuesta por valores categóricos ordinales (R y NR) convertimos en valores numéricos (R=0, NR=1) \n",
    "for i in range (len(data)):\n",
    "    if data.Target[i]=='R': #R\n",
    "        Y.append(0)\n",
    "    else:                   #NR\n",
    "        Y.append(1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación del modelo de Perceptrón Multicapa\n",
    "### 1. Separamos el conjunto de datos en entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento: 45\n",
      "Tamaño de la columna objetivo del conjunto de entrenamiento: 45\n",
      "Tamaño del conjunto de prueba: 8\n",
      "Tamaño de la columna objetivo del conjunto de prueba: 8\n"
     ]
    }
   ],
   "source": [
    "XTrain, XTest, yTrain, yTest = train_test_split(X, Y, test_size=0.15, random_state=125)\n",
    "\n",
    "print('Tamaño del conjunto de entrenamiento:', len(XTrain))\n",
    "print('Tamaño de la columna objetivo del conjunto de entrenamiento:', len(yTrain))\n",
    "print('Tamaño del conjunto de prueba:', len(XTest))\n",
    "print('Tamaño de la columna objetivo del conjunto de prueba:', len(yTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Instanciamos un GridSeacrgCV para averiguar que parámetros ajustan mejor el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=MLPClassifier(),\n",
       "             param_grid={'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
       "                         'hidden_layer_sizes': [3, 5],\n",
       "                         'max_fun': [300, 500, 1000, 5000, 10000, 15000, 20000],\n",
       "                         'max_iter': [200, 500, 1000], 'random_state': [125],\n",
       "                         'solver': ['lbfgs']})"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'max_iter': [200, 500, 1000],\n",
    "            'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "            'random_state': [125],\n",
    "            'max_fun': [300, 500,1000, 5000, 10000, 15000, 20000],\n",
    "            'hidden_layer_sizes': [3,5],\n",
    "            'solver': ['lbfgs']}\n",
    "\n",
    "# Creamos un GridSearchCV que permite evaluar y seleccionar de forma sistemática los parámetros de nuestro modelo. \n",
    "# Indicándole un modelo y los parámetros a probar, puede evaluar el rendimiento del primero en función de los \n",
    "# segundos mediante validación cruzada. \n",
    "clf = GridSearchCV(MLPClassifier(), param_grid, cv =5)\n",
    "\n",
    "clf.fit(XTrain , yTrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor estimación de parámetros según GridSearchCV:\n",
      "MLPClassifier(activation='tanh', hidden_layer_sizes=5, max_fun=300,\n",
      "              random_state=125, solver='lbfgs')\n"
     ]
    }
   ],
   "source": [
    "print(\"Mejor estimación de parámetros según GridSearchCV:\")\n",
    "print(clf.best_estimator_)\n",
    "model = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor resultado de la cross validation del modelo con mejores resultados: 0.6\n"
     ]
    }
   ],
   "source": [
    "print(\"Mejor resultado de la cross validation del modelo con mejores resultados: \" +str(clf.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicciones y estudio de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos las predicciones con el modelo óptimo sobre el conjunto de datos de entrenamiento\n",
    "yhatTrain = model.predict(XTrain)\n",
    "contTrain = 0\n",
    "\n",
    "# Comparamos con la columna Target y comprobamos cuantos aciertos ha habido\n",
    "for i in range(0,len(yTrain),1) :\n",
    "    if (yhatTrain[i] == yTrain[i]):\n",
    "        contTrain = contTrain + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos las predicciones con el modelo óptimo sobre el conjunto de datos de prueba\n",
    "yhatTest = model.predict(XTest)\n",
    "contTest = 0\n",
    "\n",
    "# Comparamos con la columna Target y comprobamos cuantos aciertos ha habido\n",
    "for i in range(0,len(yTest),1) :\n",
    "    if (yhatTest[i] == yTest[i]):\n",
    "        contTest = contTest + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión final en el conjunto de datos de entrenamiento: 0.9777777777777777\n",
      "Precisión final en el conjunto de datos de prueba: 0.75\n"
     ]
    }
   ],
   "source": [
    "print('Precisión final en el conjunto de datos de entrenamiento: ' + str(contTrain/len(yTrain)))\n",
    "print('Precisión final en el conjunto de datos de prueba: ' + str(contTest/len(yTest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matriz de confusión\n",
    "### 1. Matriz de confusión del conjunto de datos del entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Matriz de confusión (Entrenamiento)------------------\n",
      "[[22  1]\n",
      " [ 0 22]]\n",
      "Datos de entrada:  [0 1 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 1 0 1 1 0 0 0 1 1 0 0 1 1 1 1 1 0 0\n",
      " 0 1 0 1 0 1 1 1]\n",
      "Predicción:        [0 1 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 1 0 1 1 0 0 0 1 1 1 0 1 1 1 1 1 0 0\n",
      " 0 1 0 1 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "print('----------------Matriz de confusión (Entrenamiento)------------------')\n",
    "print(confusion_matrix(yTrain,yhatTrain))\n",
    "print('Datos de entrada:  ' + str(np.array(yTrain)))\n",
    "print('Predicción:        ' +str(yhatTrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos resultados pueden ser interpretados de la siguiente manera:\n",
    "1. 22 verdaderos positivos (Verdaderamente responderán al tratamiento)\n",
    "2. 22 verdaderos negativos (Verdaderamente no responderán al tratamiento)\n",
    "3. 1 falsos positivos (Fueron clasificados como mala respuesta al tratamiento, sin embargo, responderán correctamente al mismo)\n",
    "4. 0 falsos negativos (Fueron clasificados como buena respuesta al tratamiento, sin embargo, no responderán al tratamiento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Resultados obtenidos del conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        23\n",
      "           1       0.96      1.00      0.98        22\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yTrain,yhatTrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Matriz de confusión del conjunto de datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Matriz de confusión (Prueba)------------------\n",
      "[[5 2]\n",
      " [0 1]]\n",
      "Datos de entrada:  [0 0 0 1 0 0 0 0]\n",
      "Predicción:        [1 0 0 1 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print('----------------Matriz de confusión (Prueba)------------------')\n",
    "print(confusion_matrix(yTest,yhatTest))\n",
    "print('Datos de entrada:  ' + str(np.array(yTest)))\n",
    "print('Predicción:        ' +str(yhatTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos resultados pueden ser interpretados de la siguiente manera:\n",
    "1. 5 verdaderos positivos (Verdaderamente responderán al tratamiento)\n",
    "2. 1 verdaderos negativos (Verdaderamente no responderán al tratamiento)\n",
    "3. 2 falsos positivos (Fueron clasificados como mala respuesta al tratamiento, sin embargo, responderán correctamente al mismo)\n",
    "4. 0 falsos negativos (Fueron clasificados como buena respuesta al tratamiento, sin embargo, no responderán al tratamiento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Resultados obtenidos del conjunto de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.71      0.83         7\n",
      "           1       0.33      1.00      0.50         1\n",
      "\n",
      "    accuracy                           0.75         8\n",
      "   macro avg       0.67      0.86      0.67         8\n",
      "weighted avg       0.92      0.75      0.79         8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yTest,yhatTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliografía\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html?highlight=mlpclassifier#sklearn.neural_network.MLPClassifier\n",
    "\n",
    "https://moodle.upm.es/titulaciones/oficiales/pluginfile.php/10073620/mod_resource/content/1/Unit2-ClassificationRegression-NeuralNetworks.pdf\n",
    "\n",
    "https://www.llipe.com/2017/04/19/programando-un-clasificador-perceptron-en-python/\n",
    "\n",
    "https://machinelearningmastery.com/implement-perceptron-algorithm-scratch-python/"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "441f9d3ff1c529ee1e872a15f4dc348a3c02d54fb42565189cd8283cda2528b2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('mlenv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
