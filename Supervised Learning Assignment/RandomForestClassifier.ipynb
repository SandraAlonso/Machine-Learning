{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de clasificación con Random Forest \n",
    "## Autora: Sandra Alonso Paz, estudiante del Máster en Biología Computacional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importación de los datos\n",
    "### 1. Importar los datos del CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "path ='dataset18.csv'\n",
    "data = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Creamos las dos variables que utilizaremos en el modelo\n",
    "   \n",
    "    X = Atributos del modelo (columnas del CSV)\n",
    "    \n",
    "    Y = Columna target (la que queremos predecir a partir del resto de columnas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,2:23] #Seleccionamos todas las columnas quitando la columna Unnamed (id de la fila ) y la columna Target.\n",
    "Y = []\n",
    "\n",
    "# Como la columna target esta compuesta por valores categóricos ordinales (R y NR) convertimos en valores numéricos (R=0, NR=1) \n",
    "for i in range (len(data)):\n",
    "    if data.Target[i]=='R': #R\n",
    "        Y.append(0)\n",
    "    else:                   #NR\n",
    "        Y.append(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación del modelo de Random Forest\n",
    "### 1. Separamos el conjunto de datos en entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento: 34\n",
      "Tamaño de la columna objetivo del conjunto de entrenamiento: 34\n",
      "Tamaño del conjunto de prueba: 19\n",
      "Tamño de la columna objetivo del conjunto de prueba: 19\n"
     ]
    }
   ],
   "source": [
    "# Split train and test using sklearn.model_selection.train_test_split function\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X, Y, test_size=0.35, random_state=125)\n",
    "\n",
    "print('Tamaño del conjunto de entrenamiento:', len(XTrain))\n",
    "print('Tamaño de la columna objetivo del conjunto de entrenamiento:', len(yTrain))\n",
    "print('Tamaño del conjunto de prueba:', len(XTest))\n",
    "print('Tamño de la columna objetivo del conjunto de prueba:', len(yTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Instanciamos un GridSeacrgCV para averiguar que parámetros ajustan mejor el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={'bootstrap': [True, False],\n",
       "                         'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [None, 2, 5, 10, 50],\n",
       "                         'min_samples_leaf': [1, 2, 3],\n",
       "                         'min_samples_split': [2, 3, 4, 5],\n",
       "                         'n_estimators': [10, 20], 'random_state': [125]})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'min_samples_leaf': [1, 2, 3],\n",
    "              'min_samples_split': [2, 3, 4, 5],\n",
    "              'random_state':[125],\n",
    "              'n_estimators': [10, 20],\n",
    "              'bootstrap': [True, False],\n",
    "              'criterion': ['gini', 'entropy'],\n",
    "              'max_depth':[None, 2, 5, 10,50]\n",
    "              }\n",
    "\n",
    "# Creamos un GridSearchCV que permite evaluar y seleccionar de forma sistemática los parámetros de nuestro modelo. \n",
    "# Indicándole un modelo y los parámetros a probar, puede evaluar el rendimiento del primero en función de los \n",
    "# segundos mediante validación cruzada. \n",
    "clf = GridSearchCV(\n",
    "        estimator  = RandomForestClassifier(),\n",
    "        param_grid = param_grid,\n",
    "        cv=5\n",
    "       )\n",
    "\n",
    "clf.fit(XTrain , yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor estimación de parámetros según GridSearchCV:\n",
      "RandomForestClassifier(max_depth=2, min_samples_leaf=2, n_estimators=10,\n",
      "                       random_state=125)\n"
     ]
    }
   ],
   "source": [
    "print(\"Mejor estimación de parámetros según GridSearchCV:\")\n",
    "print(clf.best_estimator_)\n",
    "model = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor resultado de la cross validation del modelo con mejores resultados: 0.7380952380952381\n"
     ]
    }
   ],
   "source": [
    "print(\"Mejor resultado de la cross validation del modelo con mejores resultados: \" +str(clf.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicciones y estudio de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos las predicciones con el modelo óptimo sobre el conjunto de datos de entrenamiento\n",
    "yhatTrain = model.predict(XTrain)\n",
    "contTrain = 0\n",
    "\n",
    "# Comparamos con la columna Target y comprobamos cuantos aciertos ha habido\n",
    "for i in range(len(yTrain)) :\n",
    "    if (yhatTrain[i] == yTrain[i]):\n",
    "        contTrain = contTrain + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos las predicciones con el modelo óptimo sobre el conjunto de datos de prueba\n",
    "yhatTest = model.predict(XTest)\n",
    "contTest = 0\n",
    "\n",
    "# Comparamos con la columna Target y comprobamos cuantos aciertos ha habido\n",
    "for i in range(0,len(yTest),1) :\n",
    "    if (yhatTest[i] == yTest[i]):\n",
    "        contTest = contTest + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión final en el conjunto de datos de entrenamiento: 0.9411764705882353\n",
      "Precisión final en el conjunto de datos de prueba: 0.7894736842105263\n"
     ]
    }
   ],
   "source": [
    "print('Precisión final en el conjunto de datos de entrenamiento: ' + str(contTrain/len(yTrain)))\n",
    "print('Precisión final en el conjunto de datos de prueba: ' + str(contTest/len(yTest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matriz de confusión\n",
    "### 1. Matriz de confusión del conjunto de datos del entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Matriz de confusión (Entrenamientos)------------------\n",
      "[[13  2]\n",
      " [ 0 19]]\n",
      "Datos de entrada:  [1 1 0 1 0 0 0 1 1 0 1 1 0 0 0 1 1 0 0 1 1 1 1 1 0 0 0 1 0 1 0 1 1 1]\n",
      "Predicción:        [1 1 0 1 0 0 0 1 1 0 1 1 0 0 0 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "print('----------------Matriz de confusión (Entrenamientos)------------------')\n",
    "print(confusion_matrix(yTrain,yhatTrain))\n",
    "print('Datos de entrada:  ' + str(np.array(yTrain)))\n",
    "print('Predicción:        ' +str(yhatTrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos resultados pueden ser interpretados de la siguiente manera:\n",
    "1. 13 verdaderos positivos (Verdaderamente responderán al tratamiento)\n",
    "2. 19 verdaderos negativos (Verdaderamente no responderán al tratamiento)\n",
    "3. 2 falsos positivos (Fueron clasificados como mala respuesta al tratamiento, sin embargo, no responderán correctamenteal mismo)\n",
    "4. 0 falsos negativos (Fueron clasificados como buena respuesta al tratamiento, sin embargo, no responderán al tratamiento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Resultados obtenidos del conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93        15\n",
      "           1       0.90      1.00      0.95        19\n",
      "\n",
      "    accuracy                           0.94        34\n",
      "   macro avg       0.95      0.93      0.94        34\n",
      "weighted avg       0.95      0.94      0.94        34\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yTrain,yhatTrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Matriz de confusión del conjunto de datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Matriz de confusión (Prueba)------------------\n",
      "[[11  4]\n",
      " [ 0  4]]\n",
      "Datos de entrada:  [0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0]\n",
      "Predicción:        [1 0 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print('----------------Matriz de confusión (Prueba)------------------')\n",
    "print(confusion_matrix(yTest,yhatTest))\n",
    "print('Datos de entrada:  ' + str(np.array(yTest)))\n",
    "print('Predicción:        ' +str(yhatTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos resultados pueden ser interpretados de la siguiente manera:\n",
    "1. 11 verdaderos positivos (Verdaderamente responderán al tratamiento)\n",
    "2. 4 verdaderos negativos (Verdaderamente no responderán al tratamiento)\n",
    "3. 4 falsos positivos (Fueron clasificados como mala respuesta al tratamiento, sin embargo, responderán correctamente al mismo)\n",
    "4. 0 falsos negativos (Fueron clasificados como buena respuesta al tratamiento, sin embargo, no responderán al tratamiento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Resultados obtenidos del conjunto de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.73      0.85        15\n",
      "           1       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.79        19\n",
      "   macro avg       0.75      0.87      0.76        19\n",
      "weighted avg       0.89      0.79      0.81        19\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yTest,yhatTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliografía\n",
    "\n",
    "https://www.cienciadedatos.net/documentos/py08_random_forest_python.html\n",
    "\n",
    "https://machinelearningmastery.com/random-forest-ensemble-in-python/\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "https://www.datacamp.com/community/tutorials/random-forests-classifier-python\n",
    "\n",
    "https://towardsdatascience.com/random-forest-in-python-24d0893d51c0\n",
    "\n",
    "https://github.com/ronifernando/KNN-Python-using-Jupyter-Notebook/blob/master/KNN%20Caravan.ipynb\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "441f9d3ff1c529ee1e872a15f4dc348a3c02d54fb42565189cd8283cda2528b2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('mlenv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
